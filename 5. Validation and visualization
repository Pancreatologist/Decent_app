rm(list=ls())
library(tidyverse)
library(randomForest)
library(caret)
library(e1071)
library(adabag)
library(pROC)
library(xgboost)
library(lightgbm)
#library(catboost)
library(kknn)  
library(ggplot2)
library(ggsci)
library(adabag)
library(ResourceSelection)
library(PRROC)
#注diagnosis 为应变量
#构建模型的时候使用以下代码保存一下
#saveRDS(logisticModel, file = "lg_model.rds")
#saveRDS(RF_Model, file = "RF_Model.rds")
#saveRDS(xgb_model, file = "xgb_model.rds")
#catboost.save_model(cat_model, "catboost_model.cbm")
#saveRDS(lgb_model, file = "lgb_model.rds")
#svm比较特殊需重新构建才能绘制roc
#加载保存的模型
logisticModel <- readRDS("lg_model.rds")
RF_Model<- readRDS("RF_Model.rds")
xgb_model<- readRDS("xgb_model.rds")
lgb_model<- readRDS("lgb_model.rds")

ada_model <- readRDS("ada_model.rds")
#读取boruta跟LASSO的交集筛选出的测试集数据
data <- read.delim("boruta跟LASSO的交集_测试集.txt",
                   sep = '\t', row.names=1,header = TRUE, check.names = FALSE)

#读取boruta跟LASSO的交集
data_train <- read.delim("boruta跟LASSO的交集_训练集.txt",
                   sep = '\t', row.names=1,header = TRUE, check.names = FALSE)
data_train$diagnosis <- as.factor(data_train$diagnosis)
data$diagnosis <- factor(data$diagnosis,levels = c(0, 1))
str(data)

#-----1.混淆矩阵------
###Logistic 预测结果#######
prob_lr = predict(logisticModel, newdata = data, 
                  type = 'response')        
pred_lr <- ifelse(prob_lr > 0.5, 1, 0)   
#  Logistic 创建混淆矩阵  
data$diagnosis <- as.factor(data$diagnosis)

confusion_matrix_lr <- caret::confusionMatrix(
  factor(pred_lr,levels = c(0, 1),labels = c("0","1")), 
  data$diagnosis,
  positive = "1")   
print(confusion_matrix_lr) 


# 获取指标
metrics_lr <- data.frame(
  Accuracy = confusion_matrix_lr$overall["Accuracy"],
  Precision = confusion_matrix_lr$byClass["Precision"],
  Recall = confusion_matrix_lr$byClass["Recall"],
  F1 = confusion_matrix_lr$byClass["F1"],
  AUC = pROC::auc(response = data$diagnosis, predictor = prob_lr)
)

# 转置为垂直格式
final_metrics_lr <- metrics_lr %>% 
  t() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Metric") %>%
  rename(Value = "Accuracy")

# 保存结果
write.csv(final_metrics_lr, "lr_metrics.csv", row.names = FALSE)

# 将混淆矩阵转换为数据框
conf_matrix_df_lr <- as.data.frame(confusion_matrix_lr$table)

# 使用ggplot2绘制混淆矩阵热图
conf_plot_lr <- ggplot(conf_matrix_df_lr, aes(x =Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "#1E90FF") +  # 使用更鲜艳的颜色
  labs(
    title = "Confusion Matrix for Logistic Model",
    x = "Actual Class",
    y = "Predicted Class",
    fill = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold", color = "darkblue"),
    axis.title = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12, color = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 12, hjust = 0.5, face = "italic", color = "darkred"),
    plot.background = element_rect(fill = "grey95"),  # 设置背景颜色
    panel.background = element_rect(fill = "white")  # 设置面板背景颜色
  )
conf_plot_lr

# 保存图片
ggsave("./混淆矩阵_lr.pdf", conf_plot_lr, width = 6, height = 6)

### 随机森林模型 预测结果#####
pred_rf <- predict(RF_Model, newdata = data)  
prob_rf <- predict(RF_Model, newdata = data, 
                   type = "prob")[, 2]  # 预测属于Yes的概率  


#  随机森林模型 创建混淆矩阵  
confusion_matrix_rf <- caret::confusionMatrix(
  factor(pred_rf,levels = c(0, 1),labels = c("0","1")), 
  data$diagnosis,
  positive = "1")   # 训练集
print(confusion_matrix_rf) 



# 获取指标
metrics_rf <- data.frame(
  Accuracy = confusion_matrix_rf$overall["Accuracy"],
  Precision = confusion_matrix_rf$byClass["Precision"],
  Recall = confusion_matrix_rf$byClass["Recall"],
  F1 = confusion_matrix_rf$byClass["F1"],
  AUC = pROC::auc(response = data$diagnosis, predictor = prob_rf)
)

# 转置为垂直格式
final_metrics_rf <- metrics_rf %>% 
  t() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Metric") %>%
  rename(Value = "Accuracy")

# 保存结果
write.csv(final_metrics_rf, "rf_metrics.csv", row.names = FALSE)

# 将混淆矩阵转换为数据框
conf_matrix_df_rf <- as.data.frame(confusion_matrix_rf$table)

# 使用ggplot2绘制混淆矩阵热图
conf_plot_rf <- ggplot(conf_matrix_df_rf, aes(x =Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "#1E90FF") +  # 使用更鲜艳的颜色
  labs(
    title = "Confusion Matrix for Random Forest Model",
    x = "Actual Class",
    y = "Predicted Class",
    fill = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold", color = "darkblue"),
    axis.title = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12, color = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 12, hjust = 0.5, face = "italic", color = "darkred"),
    plot.background = element_rect(fill = "grey95"),  # 设置背景颜色
    panel.background = element_rect(fill = "white")  # 设置面板背景颜色
  )
conf_plot_rf

# 保存图片
ggsave("./混淆矩阵_rf.pdf", conf_plot_lr, width = 6, height = 6)

###支持向量机 预测结果#######
#positive_count <- sum(data_train$diagnosis == 1)
#negative_count <- sum(data_train$diagnosis == 0)
#scale_pos_weight <- negative_count / positive_count
#data_train$weights <- ifelse(data_train$diagnosis == 1, 
#                             negative_count / positive_count, 
#                             1)

svm_model <- svm(diagnosis~., data=data_train,gamma=0.1,cost=10,
                 probability = TRUE)
pred_svm  <- predict(svm_model, newdata = data)  
prob_svm <- attr(predict(svm_model, newdata = data, probability = TRUE), 
                       "probabilities")[,"1"] #预测属于Yes的概率

#  支持向量机 创建混淆矩阵  
confusion_matrix_svm <- caret::confusionMatrix(
  factor(pred_svm,levels =c("0", "1"),labels = c("0","1")), 
  data$diagnosis,
  positive = "1")   # 训练集
print(confusion_matrix_svm) 


# 获取指标
metrics_svm <- data.frame(
  Accuracy = confusion_matrix_svm$overall["Accuracy"],
  Precision = confusion_matrix_svm$byClass["Precision"],
  Recall = confusion_matrix_svm$byClass["Recall"],
  F1 = confusion_matrix_svm$byClass["F1"],
  AUC = pROC::auc(response = data$diagnosis, predictor = prob_svm)
)

# 转置为垂直格式
final_metrics_svm <- metrics_svm %>% 
  t() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Metric") %>%
  rename(Value = "Accuracy")

# 保存结果
write.csv(final_metrics_svm, "svm_metrics.csv", row.names = FALSE)

# 将混淆矩阵转换为数据框
conf_matrix_df_svm <- as.data.frame(confusion_matrix_svm$table)

# 使用ggplot2绘制混淆矩阵热图
conf_plot_svm <- ggplot(conf_matrix_df_svm, aes(x =Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "#1E90FF") +  # 使用更鲜艳的颜色
  labs(
    title = "Confusion Matrix for SVM Model",
    x = "Actual Class",
    y = "Predicted Class",
    fill = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold", color = "darkblue"),
    axis.title = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12, color = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 12, hjust = 0.5, face = "italic", color = "darkred"),
    plot.background = element_rect(fill = "grey95"),  # 设置背景颜色
    panel.background = element_rect(fill = "white")  # 设置面板背景颜色
  )
conf_plot_svm

# 保存图片
ggsave("./混淆矩阵_svm.pdf", conf_plot_lr, width = 6, height = 6)



###XGboost 预测结果#######
X_test <-data %>%
  dplyr::select(-c(diagnosis)) %>%
  as.matrix()
Y_test <-ifelse(data$diagnosis == "1", 1, 0) %>% as.numeric() #转为数值型向量
dtest <-xgb.DMatrix(data = X_test,label = Y_test)
prob_xgb <- predict(xgb_model, dtest)  
pred_xgb <- ifelse(prob_xgb > 0.5, 1, 0)  




# 创建混淆矩阵  
confusion_matrix_xgb <- caret::confusionMatrix(factor(pred_xgb,levels = c(0, 1),labels = c("0","1")), 
                                               as.factor(data$diagnosis), 
                                               positive = "1")  
print(confusion_matrix_xgb) 

# 获取指标
metrics_xgb <- data.frame(
  Accuracy = confusion_matrix_xgb$overall["Accuracy"],
  Precision = confusion_matrix_xgb$byClass["Precision"],
  Recall = confusion_matrix_xgb$byClass["Recall"],
  F1 = confusion_matrix_xgb$byClass["F1"],
  AUC = pROC::auc(response = data$diagnosis, predictor = prob_xgb)
)

# 转置为垂直格式
final_metrics_xgb <- metrics_xgb %>% 
  t() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Metric") %>%
  rename(Value = "Accuracy")

# 保存结果
write.csv(final_metrics_xgb, "xgb_metrics_train.csv", row.names = FALSE)

# 将混淆矩阵转换为数据框
conf_matrix_df_xgb <- as.data.frame(confusion_matrix_xgb$table)

# 使用ggplot2绘制混淆矩阵热图
conf_plot_xgb <- ggplot(conf_matrix_df_xgb, aes(x =Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "#1E90FF") +  # 使用更鲜艳的颜色
  labs(
    title = "Confusion Matrix for XGboost Model",
    x = "Actual Class",
    y = "Predicted Class",
    fill = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold", color = "darkblue"),
    axis.title = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12, color = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 12, hjust = 0.5, face = "italic", color = "darkred"),
    plot.background = element_rect(fill = "grey95"),  # 设置背景颜色
    panel.background = element_rect(fill = "white")  # 设置面板背景颜色
  )
conf_plot_xgb



# 保存图片
ggsave("./混淆矩阵_xgb.pdf", conf_plot_xgb, width = 6, height = 6)

###LightGBM 预测结果#######

prob_lgb <- predict(lgb_model,newdata = as.matrix(data[2:ncol(data)]),
                               type = 'prob')
pred_lgb <- predict(lgb_model,newdata = as.matrix(data[2:ncol(data)]),
                               type = 'class')


# 创建混淆矩阵  
confusion_matrix_lgb <- caret::confusionMatrix(factor(pred_lgb,levels = c(0, 1),labels = c("0","1")), 
                                               as.factor(data$diagnosis), 
                                               positive = "1")  
print(confusion_matrix_lgb) 

# 获取指标
metrics_lgb <- data.frame(
  Accuracy = confusion_matrix_lgb$overall["Accuracy"],
  Precision = confusion_matrix_lgb$byClass["Precision"],
  Recall = confusion_matrix_lgb$byClass["Recall"],
  F1 = confusion_matrix_lgb$byClass["F1"],
  AUC = pROC::auc(response = data$diagnosis, predictor = prob_lgb)
)

# 转置为垂直格式
final_metrics_lgb <- metrics_lgb %>% 
  t() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Metric") %>%
  rename(Value = "Accuracy")

# 保存结果
write.csv(final_metrics_lgb, "lgb_metrics_train.csv", row.names = FALSE)

# 将混淆矩阵转换为数据框
conf_matrix_df_lgb <- as.data.frame(confusion_matrix_lgb$table)

# 使用ggplot2绘制混淆矩阵热图
conf_plot_lgb <- ggplot(conf_matrix_df_lgb, aes(x =Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "#1E90FF") +  # 使用更鲜艳的颜色
  labs(
    title = "Confusion Matrix for LightGBM Model",
    x = "Actual Class",
    y = "Predicted Class",
    fill = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20, face = "bold", color = "darkblue"),
    axis.title = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12, color = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 12, hjust = 0.5, face = "italic", color = "darkred"),
    plot.background = element_rect(fill = "grey95"),  # 设置背景颜色
    panel.background = element_rect(fill = "white")  # 设置面板背景颜色
  )
conf_plot_lgb

ggsave("./混淆矩阵_Lgb.pdf", conf_plot_xgb, width = 6, height = 6)


#-----2.单次ROC曲线绘制------
# 计算ROC对象
library(PRROC)
library(ROCR)
roc_lr <- roc(data$diagnosis, as.numeric(prob_lr))
roc_rf <- roc(data$diagnosis, as.numeric(prob_rf))
roc_svm <- roc(data$diagnosis, as.numeric(prob_svm))
roc_xgb <- roc(data$diagnosis, as.numeric(prob_xgb))
roc_lgb <- roc(data$diagnosis, as.numeric(prob_lgb))

# 计算AUC值
auc_lr <- roc_lr$auc # AUC 0.704, 0.596-0.739
auc_rf <- roc_rf$auc # 0.828, 0.710-0.835
auc_svm <- roc_svm$auc # 0.744, 0.565-0.782
auc_xgb <- roc_xgb$auc # 0.828, 0.739-0.844
auc_lgb <- roc_lgb$auc #0.813, 0.623-0.881
roc_dnn, 0.844, 0.783-0.849

#save.image('ML的相关结果.RData')

# 创建数据框，包含每个模型的 AUC 值和 ROC 对象
roc_data <- list(
  Model = c("Logistic Regression","Random Forest","SVM", 
            "XGBoost","LightGBM",
            'Deep Neural Networks'),
  AUC = c(auc_lr,auc_rf,auc_svm, auc_xgb,auc_lgb,
          auc_dnn),  # 实际模型的 AUC 值
  ROC = list(roc_lr,roc_rf,roc_svm, roc_xgb,roc_lgb,
             roc_dnn)  # 实际模型的 ROC 对象
)

roc_data$Model <- factor(roc_data$Model,
                         levels = c("Logistic Regression","XGBoost",
                                    "Random Forest","LightGBM",
                                    "SVM","Deep Neural Networks"))
# 提取 ROC 曲线的数据并转换为数据框
roc_curves <- lapply(seq_along(roc_data$ROC), function(i) {
  roc_obj <- roc_data$ROC[[i]]
  data.frame(
    Sensitivity = roc_obj$sensitivities,
    Specificity = roc_obj$specificities,
    Model = roc_data$Model[i]
  )
})

# 将列表合并为一个数据框
roc_curves <- do.call(rbind, roc_curves)

# 对 ROC 对象进行平滑处理
smoothed_rocs <- lapply(roc_data$ROC, smooth, method = "density")  # 使用密度平滑方法

# 添加 AUC 值到图例标签
roc_data$Label <- paste(roc_data$Model, " (AUC = ", round(roc_data$AUC, 3), ")", sep = "")
# 绘制平滑 ROC 曲线
roc_plot <- ggroc(smoothed_rocs, linetype = 1, size = 1.2) +
  scale_color_bmj(labels = roc_data$Label) +  # 使用 Lancet 颜色主题并添加 AUC 标签
  labs(title = "ROC Curves for Models",
       x = "1 - Specificity",
       y = "Sensitivity") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "bottom",
    legend.text = element_text(size = 10)
  ) +
  guides(color = guide_legend(ncol = 3, byrow = TRUE))  # 图例分两列显示

# 显示图形
roc_plot

# 保存图片
ggsave("./单次ROC.pdf", roc_plot, width = 6, height = 6)

#-----3.校准曲线绘制------
library(scales)   # 提供刻度格式化工具

# 预测结果及真实标签汇总为一个数据框
calibration_data <- data.frame(
  Model = c(rep("Logistic Regression", length(prob_lr)),
            rep("Random Forest", length(prob_rf)),
            rep("SVM", length(prob_svm)),
            rep("XGBoost", length(prob_xgb)),
            rep("LightGBM", length(prob_lgb)),
            rep("Deep Neural Networks", length(prob_dnn))
  ),
  Probability = c(prob_lr, 
                  prob_rf,
                  prob_svm,
                  prob_xgb,
                  prob_lgb,
                  #prob_ada,
                  as.numeric(prob_dnn)),
  Actual = as.numeric(c(data$diagnosis)) - 1  # 将因子转为数值
)


calibration_data$Model <- factor(calibration_data$Model,
                           levels = c("Logistic Regression","XGBoost",
                                      "Random Forest","LightGBM",
                                      "SVM","Deep Neural Networks"))


#校准曲线
calibration_plot <- ggplot(calibration_data, aes(x = Probability, y = Actual,
                                                 color = Model)) +
  scale_color_bmj()+
  geom_smooth(method = "loess", se = FALSE, linewidth = 1.5, span = 0.9) +  
  #方法有loess、gam 
  # 增加 span 参数,较大的 span 值会产生更平滑的曲线，而较小的 span 值会使曲线更贴近数据点
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black", linewidth = 1) +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) +
  labs(
    title = "Calibration Curves",
    x = "Actual Probability",
    y = "Observed Proportion"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "bottom",
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10),
    axis.line = element_line(colour = "black")
  ) 
calibration_plot

ggsave("./校准曲线.pdf", calibration_plot, width = 6, height = 6)


# 定义计算各指标的函数
calculate_brier_score <- function(probabilities, actual) {
  mean((probabilities - actual)^2)
}
calculate_log_loss <- function(probabilities, actual) {
  # 将预测概率裁剪到 (0, 1) 范围内
  probabilities <- pmax(pmin(probabilities, 1 - 1e-10), 1e-10)
  -mean(actual * log(probabilities) + (1 - actual) * log(1 - probabilities))
}
calculate_calibration_slope <- function(probabilities, actual) {
  # 将预测概率裁剪到 (0, 1) 范围内
  probabilities <- pmax(pmin(probabilities, 1 - 1e-10), 1e-10)
  fit <- glm(actual ~ log(probabilities / (1 - probabilities)), family = binomial)
  coef(fit)[2]
}
# calculate_calibration_intercept 函数
calculate_calibration_intercept <- function(probabilities, actual) {
  # 将预测概率裁剪到 (0, 1) 范围内
  probabilities <- pmax(pmin(probabilities, 1 - 1e-10), 1e-10)
  # 使用 suppressWarnings 忽略 glm.fit 的警告
  suppressWarnings({
    fit <- glm(actual ~ 1, offset = log(probabilities / (1 - probabilities)), family = binomial)
    coef(fit)[1]
  })
}

calculate_hl_test <- function(probabilities, actual, n_groups = 10) {
  hoslem.test(actual, probabilities, g = n_groups)$p.value
}
calculate_ece <- function(probabilities, actual, n_bins = 10) {
  bin_indices <- cut(probabilities, breaks = seq(0, 1, length.out = n_bins + 1), include.lowest = TRUE)
  ece <- 0
  for (i in levels(bin_indices)) {
    bin_samples <- bin_indices == i
    if (sum(bin_samples) > 0) {  # 确保分箱中有样本
      bin_prob <- mean(probabilities[bin_samples])
      bin_actual <- mean(actual[bin_samples])
      ece <- ece + abs(bin_prob - bin_actual) * sum(bin_samples) / length(actual)
    }
  }
  ece
}
#  calculate_mce 函数
calculate_mce <- function(probabilities, actual, n_bins = 10) {
  bin_indices <- cut(probabilities, breaks = seq(0, 1, length.out = n_bins + 1), include.lowest = TRUE)
  mce <- 0
  for (i in levels(bin_indices)) {
    bin_samples <- bin_indices == i
    if (sum(bin_samples) > 0) {  # 确保分箱中有样本
      bin_prob <- mean(probabilities[bin_samples])
      bin_actual <- mean(actual[bin_samples])
      mce <- max(mce, abs(bin_prob - bin_actual))
    }
  }
  mce
}

# 计算每个模型的指标
metrics_summary <- calibration_data %>%
  group_by(Model) %>%
  summarise(
    Brier_Score = calculate_brier_score(Probability, Actual),
    Log_Loss = calculate_log_loss(Probability, Actual),
    Calibration_Slope = calculate_calibration_slope(Probability, Actual),
    Calibration_Intercept = calculate_calibration_intercept(Probability, Actual),
    HL_Test_P_Value = calculate_hl_test(Probability, Actual),
    ECE = calculate_ece(Probability, Actual),
    MCE = calculate_mce(Probability, Actual)
  )

# 打印指标汇总表
print(metrics_summary)

# 保存结果到CSV文件
write.csv(metrics_summary, file = "calibration_metrics_summary.csv", row.names = FALSE)


#-----4.DCA曲线绘制------
library(rmda)
dca_data <- data.frame(Result = as.numeric(data$diagnosis)-1, 
                       prob_lr, 
                       prob_rf,
                       prob_svm,
                       prob_xgb,
                       prob_lgb,
                       prob_dnn)


dca.result_lr <- decision_curve(Result ~ prob_lr, 
                                data = dca_data, 
                                family = "binomial",
                                thresholds = seq(0, 1, by = .01),
                                bootstraps = 10)

dca.result_rf <- decision_curve(Result ~ prob_rf, 
                                data = dca_data, 
                                family = "binomial",
                                thresholds = seq(0, 1, by = .01),
                                bootstraps = 10)

dca.result_svm <- decision_curve(Result ~ prob_svm, 
                                data = dca_data, 
                                family = "binomial",
                                thresholds = seq(0, 1, by = .01),
                                bootstraps = 10)

dca.result_xgb <- decision_curve(Result ~ prob_xgb, 
                                 data = dca_data, 
                                 family = "binomial",
                                 thresholds = seq(0, 1, by = .01),
                                 bootstraps = 10)

dca.result_lgb <- decision_curve(Result ~ prob_lgb, 
                                data = dca_data, 
                                family = "binomial",
                                thresholds = seq(0, 1, by = .01),
                                bootstraps = 10)
dca.result_dnn <- decision_curve(Result ~ prob_dnn, 
                                 data = dca_data, 
                                 family = "binomial",
                                 thresholds = seq(0, 1, by = .01),
                                 bootstraps = 10)

pdf("decision_curve_plot.pdf", width = 8, height = 6)  # PDF 文件
plot_decision_curve(
  list(dca.result_lr,dca.result_xgb,
       dca.result_rf,dca.result_lgb,
       dca.result_svm,dca.result_dnn),  # 传入包含决策曲线分析结果的列表
  curve.names = c("Logistic Regression","XGBoost",
                  "Random Forest","LightGBM",
                  "SVM","Deep Neural Networks"),
  col = c("#2A6EBBFF",  
          "#F0AB00FF",  
          "#C50084FF",  
          "#7D5CC6FF",  
          "#E37222FF", 
          "#69BE28FF"  ), 
  lwd = 2,  # 设置线宽
  confidence.intervals = FALSE, # 禁用置信区间
  legend.position = ("none")  
)

# 手动添加图例
legend("bottomright", 
       legend = c("Logistic Regression","XGBoost",
                  "Random Forest","LightGBM",
                  "SVM","Deep Neural Networks"),
       col = c("#2A6EBBFF",  
               "#F0AB00FF",  
               "#C50084FF",  
               "#7D5CC6FF",  
               "#E37222FF", 
               "#69BE28FF"),
       lwd = 2,
       cex = 0.6,  # 通过调整cex改变字体大小
       bty = "y",   # 无边框
       y.intersp = 0.8,    # 调整条目之间的间距
       x.intersp = 0.5,    # 调整颜色线条与标签之间的水平间距
       text.width = 0.15,  # 自动调整宽度
       inset = c(0.1, 0.5)) # 控制图例相对于绘图区的外边距)  
dev.off()



#### CIC曲线
plot_clinical_impact(dca.result_dnn, col = "#69BE28FF",
                     population.size = 287,    #样本量1000
                     cost.benefit.axis = T,     #显示损失-收益坐标轴
                     n.cost.benefits= 8,      
                     confidence.intervals= T)



#-----5.shap可视化-----

#加载模型
rm(list=ls())
library(kernelshap)
library(shapviz)
library(ggplot2)
# 定义模型文件路径
model_files <- c("lg_model.rds", "RF_Model.rds", 
                 "xgb_model.rds", "lgb_model.rds", "dnn_model.rds")

# 使用循环加载每个模型并存储到不同的变量中
for (file in model_files) {
  # 提取模型名称（去掉文件扩展名）
  model_name <- sub(".rds", "", file)
  
  # 加载模型并存储到变量中
  assign(model_name, readRDS(file))
  
  # 打印加载的模型以确认
  print(get(model_name))
}


#分组变量转为因子
data$diagnosis <- ifelse(data$diagnosis == "1", 1, 0)
data$diagnosis <- as.factor(data$diagnosis)
data_test$diagnosis <- ifelse(data_test$diagnosis == "1", 1, 0)
data_test$diagnosis <- as.factor(data_test$diagnosis)
str(data)
#分离特征和应变量
target <- "diagnosis"
features <- data[, -which(names(data) == "diagnosis")]
# 设置样本量和准备数据
n <- 287  # 样本量
traindata_matrix <- as.matrix(data_test[1:n, -1])
bg_X_matrix <- as.matrix(data_test[1:n, -1])  # 背景数据集

#dnn
explain_kernel_dnn <- kernelshap(nn.fit, 
                                 data_test[1:n, -1], 
                                 bg_X = data_test[1:50, -1])  #有验证集的时候用验证集
shap_value_dnn <- shapviz(explain_kernel_dnn,
                          data_test[1:n, -1], which_class = 2,
                          interactions=TRUE) 
sv_interaction(shap_value_dnn)
sv_importance(shap_value_dnn)

x <- c("age" ,"platelets_max","albumin_min","bun_min",
       "calcium_min","potassium_min","abs_monocytes_max","abs_neutrophils_min",
       "pt_max","ptt_max","ld_ldh_min")

xvars <- c('TyG','age','bun_min',"platelets_max","potassium_min","ptt_max") 


sv_dependence(shap_value_dnn,
              v= 'TyG')

sv_force(shap_value_dnn,row_id=1)
p1 <- sv_waterfall(shap_value_dnn,row_id=1L)
p2 <- sv_importance(shap_value_dnn,kind="beeswarm")
p3 <- sv_dependence(shap_value_dnn,xvars)

